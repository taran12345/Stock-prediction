{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14058 entries, 0 to 14057\n",
      "Data columns (total 7 columns):\n",
      "Date       14058 non-null object\n",
      "Open       14058 non-null float64\n",
      "High       14058 non-null float64\n",
      "Low        14058 non-null float64\n",
      "Close      14058 non-null float64\n",
      "Volume     14058 non-null int64\n",
      "OpenInt    14058 non-null int64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 768.9+ KB\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame(pd.read_csv(\"stock.txt\", sep=','))\n",
    "a.head()\n",
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6277</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>2575579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>1764749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>2194010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.5798</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>3255244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.5716</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>3696430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low   Close   Volume\n",
       "0  0.6277  0.6362  0.6201  0.6201  2575579\n",
       "1  0.6201  0.6201  0.6122  0.6201  1764749\n",
       "2  0.6201  0.6201  0.6037  0.6122  2194010\n",
       "3  0.6122  0.6122  0.5798  0.5957  3255244\n",
       "4  0.5957  0.5957  0.5716  0.5957  3696430"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.drop(\"Date\", axis=1)\n",
    "c=b.drop(\"OpenInt\", axis=1)\n",
    "Stock=c\n",
    "Stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock[\"Volume\"] = Stock[\"Volume\"]/Stock[\"Volume\"].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6277</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.002756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.001888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.002348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.5798</td>\n",
       "      <td>0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.5716</td>\n",
       "      <td>0.003955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low    Volume\n",
       "0  0.6277  0.6362  0.6201  0.002756\n",
       "1  0.6201  0.6201  0.6122  0.001888\n",
       "2  0.6201  0.6201  0.6037  0.002348\n",
       "3  0.6122  0.6122  0.5798  0.003483\n",
       "4  0.5957  0.5957  0.5716  0.003955"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Stock.drop(\"Close\", axis=1)\n",
    "Y = Stock[\"Close\"] \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14058, 4)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y) \n",
    "Y=Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14058, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bz we want matrix in (nx,m) form so we take transpose\n",
    "X_train = X_train.T \n",
    "X_test = X_test.T\n",
    "Y_train = Y_train.T \n",
    "Y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9840)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9840)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step is to initialize the parameters\n",
    "def initialize_parameters(n_a,n_x,n_y): \n",
    "    Wf = np.random.randn(n_a, n_a+n_x)\n",
    "    bf = np.random.randn(n_a,1)\n",
    "    Wi = np.random.randn(n_a, n_a+n_x)\n",
    "    bi = np.random.randn(n_a,1)\n",
    "    Wo = np.random.randn(n_a, n_a+n_x)\n",
    "    bo = np.random.randn(n_a,1)\n",
    "    Wc = np.random.randn(n_a, n_a+n_x)\n",
    "    bc = np.random.randn(n_a,1)\n",
    "    Wy = np.random.randn(n_y,n_a)\n",
    "    by = np.random.randn(n_y,1)\n",
    "    \n",
    "    parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helping function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell_forward(xt,a_prev,c_prev,parameters):\n",
    "#     parameters is dictionary if we want to access Wf then we have to write parameters[Wf], so to avoid writting this \n",
    "#     we done this\n",
    "    Wf = parameters[\"Wf\"]\n",
    "    bf = parameters[\"bf\"]\n",
    "    Wi = parameters[\"Wi\"]\n",
    "    bi = parameters[\"bi\"]\n",
    "    Wc = parameters[\"Wc\"]\n",
    "    bc = parameters[\"bc\"]\n",
    "    Wo = parameters[\"Wo\"]\n",
    "    bo = parameters[\"bo\"]\n",
    "    Wy = parameters[\"Wy\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    n_x,e = xt.shape\n",
    "    n_y, n_a = Wy.shape\n",
    "#     print(\"lstm_cell_forward\")\n",
    "    concat = np.zeros((n_a+n_x,e))\n",
    "    concat[: n_a,:] = a_prev\n",
    "    concat[n_a :,:] = xt\n",
    "    \n",
    "    ft = sigmoid(np.dot(Wf,concat) +bf)\n",
    "    it = sigmoid(np.dot(Wi,concat) +bi)\n",
    "    cct = np.tanh(np.dot(Wc,concat)+bc)\n",
    "    c_next = (ft * c_prev) + (it * cct)\n",
    "    ot = sigmoid(np.dot(Wo, concat)+bo)\n",
    "    a_next = ot*(np.tanh(c_next))\n",
    "    \n",
    "    yt_pred = np.dot(Wy, a_next)+by\n",
    "    \n",
    "    cache = (a_next, c_next, a_prev, c_prev, ft,it,cct,ot,xt,parameters)\n",
    "    \n",
    "    return a_next, c_next, yt_pred, cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_forward(x,a0,parameters):\n",
    "    \n",
    "    caches = []\n",
    "\n",
    "    n_x,T_x = x.shape\n",
    "    n_y, n_a = parameters[\"Wy\"].shape\n",
    "        \n",
    "    a = np.zeros((n_a,T_x))\n",
    "    c = np.zeros((n_a,T_x))\n",
    "    y = np.zeros((n_y,T_x))\n",
    "    \n",
    "#     print(\"lstm_forward\")\n",
    "        \n",
    "    a_next = a0\n",
    "    c_next = np.zeros(a_next.shape)\n",
    "    \n",
    "    for t in range(T_x):\n",
    "        a_next, c_next,yt,cache = lstm_cell_forward(x[:,t].reshape(-1,1),a_next,c_next,parameters)\n",
    "        a[:,t] = a_next.reshape(-1,)\n",
    "        c[:,t] = c_next.reshape(-1,)\n",
    "        y[:,t] = yt.reshape(-1,)\n",
    "        \n",
    "        caches.append(cache)\n",
    "        \n",
    "    caches = (caches, x)\n",
    "\n",
    "    return a,y,c,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y,y):\n",
    "#     print(\"compute\")\n",
    "    cost = ((1/2)*(np.power((y-Y),2)))\n",
    "    YH = (y-Y)\n",
    "    return cost, YH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell_backward(da_next, dc_next, cache, y_h):\n",
    "    \n",
    "    (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) = cache\n",
    "\n",
    "    \n",
    "    n_x,e = xt.shape\n",
    "    n_a,e = a_next.shape\n",
    "#     print(\"stm_cell_backward\")\n",
    "    dot =   da_next*np.tanh(c_next)\n",
    "    dcct = (da_next*ot*(1-np.power(np.tanh(c_next), 2))+dc_next)*it\n",
    "    dit =  (da_next*ot*(1-np.power(np.tanh(c_next), 2))+dc_next)*cct\n",
    "    dft =  (da_next*ot*(1-np.power(np.tanh(c_next), 2))+dc_next)*c_prev\n",
    "    \n",
    "    dit =  dit*it*(1-it)\n",
    "    dft =  dft*ft*(1-ft)\n",
    "    dot =  dot*ot*(1-ot)\n",
    "    dcct = dcct*(1-np.power(cct, 2))\n",
    "    \n",
    "    concat = np.zeros((n_x + n_a, e))\n",
    "    concat[: n_a, :] = a_prev\n",
    "    concat[n_a :, :] = xt\n",
    "    \n",
    "    dWf = np.dot(dft, concat.T)\n",
    "    dWi = np.dot(dit, concat.T)\n",
    "    dWc = np.dot(dcct, concat.T)\n",
    "    dWo = np.dot(dot, concat.T)\n",
    "    dbf = np.sum(dft, axis=1, keepdims=True)\n",
    "    dbi = np.sum(dit, axis=1, keepdims=True)\n",
    "    dbc = np.sum(dcct, axis=1, keepdims=True)\n",
    "    dbo = np.sum(dot, axis=1, keepdims=True)\n",
    "    \n",
    "    dWy = np.dot(y_h , a_next.T)\n",
    "    dby = np.sum(y_h, axis=1, keepdims=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    da_prevx = np.dot(parameters['Wf'].T, dft) + np.dot(parameters['Wo'].T, dot) + np.dot(parameters['Wi'].T, dit) + np.dot(parameters['Wc'].T, dcct)  \n",
    "    da_prev = da_prevx[: n_a, :]\n",
    "    dc_prev = (da_next*ot*(1-np.power(np.tanh(c_next), 2))+dc_next)*ft\n",
    "    dxt = da_prevx[n_a :, :]\n",
    "    \n",
    "    gradients = {\"dxt\": dxt, \"da_prev\": da_prev, \"dc_prev\": dc_prev, \"dWf\": dWf,\"dbf\": dbf, \"dWi\": dWi,\"dbi\": dbi,\n",
    "                \"dWc\": dWc,\"dbc\": dbc, \"dWo\": dWo,\"dbo\": dbo, \"dWy\":dWy,\"dby\":dby}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_backward(a, caches,YH):\n",
    "    (caches, x) = caches\n",
    "    (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    n_a, T_x = a.shape\n",
    "    n_x,e = x1.shape\n",
    "    da = np.dot(parameters[\"Wy\"].T , YH)\n",
    "    dx = np.zeros((n_x, T_x))\n",
    "    da0 = np.zeros((n_a, e))\n",
    "    da_prev = np.zeros((n_a, e))\n",
    "    dc_prev = np.zeros((n_a, e))\n",
    "    dWf = np.zeros((n_a, n_a + n_x))\n",
    "    dWi = np.zeros((n_a, n_a + n_x))\n",
    "    dWc = np.zeros((n_a, n_a + n_x))\n",
    "    dWo = np.zeros((n_a, n_a + n_x))\n",
    "    dWy = np.zeros((1, n_a))\n",
    "    dby = np.zeros((1,e))\n",
    "    dbf = np.zeros((n_a, 1))\n",
    "    dbi = np.zeros((n_a, 1))\n",
    "    dbc = np.zeros((n_a, 1))\n",
    "    dbo = np.zeros((n_a, 1))\n",
    "    \n",
    "    \n",
    "    for t in reversed(range(T_x)):\n",
    "        gradients = lstm_cell_backward(da[:,t].reshape(-1,1) + da_prev, dc_prev, caches[t], YH[:,t].reshape(-1,1))\n",
    "        \n",
    "        dWf = gradients[\"dWf\"]\n",
    "        dWi = gradients[\"dWi\"]\n",
    "        dWc = gradients[\"dWc\"]\n",
    "        dWo = gradients[\"dWo\"]\n",
    "        dWy = gradients[\"dWy\"]\n",
    "        dbf = gradients[\"dbf\"]\n",
    "        dbi = gradients[\"dbi\"]\n",
    "        dbc = gradients[\"dbc\"]\n",
    "        dbo = gradients[\"dbo\"]\n",
    "        dby = gradients[\"dby\"]\n",
    "        \n",
    "        \n",
    "    da0 = gradients[\"da_prev\"]\n",
    "    \n",
    "    gradients = {\"dx\": dx, \"da0\": da0, \"dWf\": dWf,\"dbf\": dbf, \"dWi\": dWi,\"dbi\": dbi,\n",
    "                \"dWc\": dWc,\"dbc\": dbc, \"dWo\": dWo,\"dbo\": dbo, \"dWy\":dWy, \"dby\":dby}\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, lr):\n",
    "\n",
    "    parameters['Wf'] += -lr * gradients['dWf']\n",
    "    parameters['bf'] += -lr * gradients['dbf']\n",
    "    parameters['Wi'] += -lr * gradients['dWi']\n",
    "    parameters['bi'] += -lr * gradients['dbi']\n",
    "    parameters['Wc'] += -lr * gradients['dWc']\n",
    "    parameters['bc'] += -lr * gradients['dbc']\n",
    "    parameters['Wo'] += -lr * gradients['dWo']\n",
    "    parameters['bo'] += -lr * gradients['dbo']\n",
    "    parameters['Wy'] += -lr * gradients['dWy']\n",
    "    parameters['bo'] += -lr * gradients['dbo']\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y,num_iterations=2000,learning_rate=0.001,print_cost=True):\n",
    "    costs = []\n",
    "    n_x,T_x = X.shape\n",
    "    n_y,T_x = Y.shape\n",
    "    n_a = 5\n",
    "\n",
    "    parameters = initialize_parameters(n_a,n_x,n_y)\n",
    "    a0 = np.random.randn(n_a,1)\n",
    "    for i in range(0,num_iterations):\n",
    "        a,y,c,caches = lstm_forward(X,a0, parameters)\n",
    "\n",
    "        cost,YH = compute_cost(Y,y)\n",
    "        cost = np.sum(cost)/T_x\n",
    "        \n",
    "        gradients = lstm_backward(a,caches,YH)\n",
    "        a0 +=learning_rate * gradients[\"da0\"]\n",
    "        parameters = update_parameters(parameters,gradients,learning_rate)\n",
    "        if print_cost:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost:\n",
    "            costs.append(cost)\n",
    "        \n",
    "#     plt.plot(np.squeeze(costs))\n",
    "#     plt.ylabel('cost')\n",
    "#     plt.xlabel('iterations (per tens)')\n",
    "#     plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "#     plt.show()\n",
    "    \n",
    "    return parameters, a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 106.299426\n",
      "Cost after iteration 1: 105.380605\n",
      "Cost after iteration 2: 104.470951\n",
      "Cost after iteration 3: 103.570400\n",
      "Cost after iteration 4: 102.678888\n",
      "Cost after iteration 5: 101.796352\n",
      "Cost after iteration 6: 100.922729\n",
      "Cost after iteration 7: 100.057956\n",
      "Cost after iteration 8: 99.201970\n",
      "Cost after iteration 9: 98.354711\n",
      "Cost after iteration 10: 97.516116\n",
      "Cost after iteration 11: 96.686124\n",
      "Cost after iteration 12: 95.864675\n",
      "Cost after iteration 13: 95.051708\n",
      "Cost after iteration 14: 94.247164\n",
      "Cost after iteration 15: 93.450983\n",
      "Cost after iteration 16: 92.663105\n",
      "Cost after iteration 17: 91.883472\n",
      "Cost after iteration 18: 91.112026\n",
      "Cost after iteration 19: 90.348708\n",
      "Cost after iteration 20: 89.593460\n",
      "Cost after iteration 21: 88.846226\n",
      "Cost after iteration 22: 88.106949\n",
      "Cost after iteration 23: 87.375571\n",
      "Cost after iteration 24: 86.652036\n",
      "Cost after iteration 25: 85.936289\n",
      "Cost after iteration 26: 85.228274\n",
      "Cost after iteration 27: 84.527936\n",
      "Cost after iteration 28: 83.835220\n",
      "Cost after iteration 29: 83.150072\n",
      "Cost after iteration 30: 82.472437\n",
      "Cost after iteration 31: 81.802261\n",
      "Cost after iteration 32: 81.139492\n",
      "Cost after iteration 33: 80.484076\n",
      "Cost after iteration 34: 79.835960\n",
      "Cost after iteration 35: 79.195091\n",
      "Cost after iteration 36: 78.561418\n",
      "Cost after iteration 37: 77.934890\n",
      "Cost after iteration 38: 77.315453\n",
      "Cost after iteration 39: 76.703058\n",
      "Cost after iteration 40: 76.097653\n",
      "Cost after iteration 41: 75.499188\n",
      "Cost after iteration 42: 74.907614\n",
      "Cost after iteration 43: 74.322879\n",
      "Cost after iteration 44: 73.744934\n",
      "Cost after iteration 45: 73.173731\n",
      "Cost after iteration 46: 72.609220\n",
      "Cost after iteration 47: 72.051353\n",
      "Cost after iteration 48: 71.500082\n",
      "Cost after iteration 49: 70.955358\n",
      "Cost after iteration 50: 70.417134\n",
      "Cost after iteration 51: 69.885363\n",
      "Cost after iteration 52: 69.359997\n",
      "Cost after iteration 53: 68.840990\n",
      "Cost after iteration 54: 68.328295\n",
      "Cost after iteration 55: 67.821866\n",
      "Cost after iteration 56: 67.321658\n",
      "Cost after iteration 57: 66.827625\n",
      "Cost after iteration 58: 66.339720\n",
      "Cost after iteration 59: 65.857901\n",
      "Cost after iteration 60: 65.382121\n",
      "Cost after iteration 61: 64.912336\n",
      "Cost after iteration 62: 64.448503\n",
      "Cost after iteration 63: 63.990577\n",
      "Cost after iteration 64: 63.538515\n",
      "Cost after iteration 65: 63.092274\n",
      "Cost after iteration 66: 62.651810\n",
      "Cost after iteration 67: 62.217081\n",
      "Cost after iteration 68: 61.788045\n",
      "Cost after iteration 69: 61.364658\n",
      "Cost after iteration 70: 60.946880\n",
      "Cost after iteration 71: 60.534669\n",
      "Cost after iteration 72: 60.127983\n",
      "Cost after iteration 73: 59.726781\n",
      "Cost after iteration 74: 59.331023\n",
      "Cost after iteration 75: 58.940667\n",
      "Cost after iteration 76: 58.555673\n",
      "Cost after iteration 77: 58.176003\n",
      "Cost after iteration 78: 57.801614\n",
      "Cost after iteration 79: 57.432469\n",
      "Cost after iteration 80: 57.068528\n",
      "Cost after iteration 81: 56.709751\n",
      "Cost after iteration 82: 56.356100\n",
      "Cost after iteration 83: 56.007537\n",
      "Cost after iteration 84: 55.664022\n",
      "Cost after iteration 85: 55.325519\n",
      "Cost after iteration 86: 54.991990\n",
      "Cost after iteration 87: 54.663396\n",
      "Cost after iteration 88: 54.339700\n",
      "Cost after iteration 89: 54.020866\n",
      "Cost after iteration 90: 53.706856\n",
      "Cost after iteration 91: 53.397635\n",
      "Cost after iteration 92: 53.093165\n",
      "Cost after iteration 93: 52.793411\n",
      "Cost after iteration 94: 52.498336\n",
      "Cost after iteration 95: 52.207905\n",
      "Cost after iteration 96: 51.922083\n",
      "Cost after iteration 97: 51.640835\n",
      "Cost after iteration 98: 51.364125\n",
      "Cost after iteration 99: 51.091919\n",
      "Cost after iteration 100: 50.824182\n",
      "Cost after iteration 101: 50.560879\n",
      "Cost after iteration 102: 50.301978\n",
      "Cost after iteration 103: 50.047444\n",
      "Cost after iteration 104: 49.797244\n",
      "Cost after iteration 105: 49.551343\n",
      "Cost after iteration 106: 49.309710\n",
      "Cost after iteration 107: 49.072310\n",
      "Cost after iteration 108: 48.839112\n",
      "Cost after iteration 109: 48.610082\n",
      "Cost after iteration 110: 48.385189\n",
      "Cost after iteration 111: 48.164399\n",
      "Cost after iteration 112: 47.947683\n",
      "Cost after iteration 113: 47.735007\n",
      "Cost after iteration 114: 47.526340\n",
      "Cost after iteration 115: 47.321651\n",
      "Cost after iteration 116: 47.120908\n",
      "Cost after iteration 117: 46.924082\n",
      "Cost after iteration 118: 46.731141\n",
      "Cost after iteration 119: 46.542055\n",
      "Cost after iteration 120: 46.356794\n",
      "Cost after iteration 121: 46.175326\n",
      "Cost after iteration 122: 45.997624\n",
      "Cost after iteration 123: 45.823656\n",
      "Cost after iteration 124: 45.653394\n",
      "Cost after iteration 125: 45.486808\n",
      "Cost after iteration 126: 45.323870\n",
      "Cost after iteration 127: 45.164549\n",
      "Cost after iteration 128: 45.008818\n",
      "Cost after iteration 129: 44.856648\n",
      "Cost after iteration 130: 44.708010\n",
      "Cost after iteration 131: 44.562877\n",
      "Cost after iteration 132: 44.421220\n",
      "Cost after iteration 133: 44.283012\n",
      "Cost after iteration 134: 44.148225\n",
      "Cost after iteration 135: 44.016832\n",
      "Cost after iteration 136: 43.888805\n",
      "Cost after iteration 137: 43.764117\n",
      "Cost after iteration 138: 43.642742\n",
      "Cost after iteration 139: 43.524653\n",
      "Cost after iteration 140: 43.409824\n",
      "Cost after iteration 141: 43.298227\n",
      "Cost after iteration 142: 43.189837\n",
      "Cost after iteration 143: 43.084627\n",
      "Cost after iteration 144: 42.982573\n",
      "Cost after iteration 145: 42.883648\n",
      "Cost after iteration 146: 42.787826\n",
      "Cost after iteration 147: 42.695084\n",
      "Cost after iteration 148: 42.605394\n",
      "Cost after iteration 149: 42.518733\n",
      "Cost after iteration 150: 42.435075\n",
      "Cost after iteration 151: 42.354397\n",
      "Cost after iteration 152: 42.276672\n",
      "Cost after iteration 153: 42.201878\n",
      "Cost after iteration 154: 42.129990\n",
      "Cost after iteration 155: 42.060983\n",
      "Cost after iteration 156: 41.994835\n",
      "Cost after iteration 157: 41.931521\n",
      "Cost after iteration 158: 41.871018\n",
      "Cost after iteration 159: 41.813302\n",
      "Cost after iteration 160: 41.758350\n",
      "Cost after iteration 161: 41.706140\n",
      "Cost after iteration 162: 41.656648\n",
      "Cost after iteration 163: 41.609852\n",
      "Cost after iteration 164: 41.565728\n",
      "Cost after iteration 165: 41.524255\n",
      "Cost after iteration 166: 41.485410\n",
      "Cost after iteration 167: 41.449172\n",
      "Cost after iteration 168: 41.415517\n",
      "Cost after iteration 169: 41.384424\n",
      "Cost after iteration 170: 41.355872\n",
      "Cost after iteration 171: 41.329839\n",
      "Cost after iteration 172: 41.306304\n",
      "Cost after iteration 173: 41.285244\n",
      "Cost after iteration 174: 41.266640\n",
      "Cost after iteration 175: 41.250470\n",
      "Cost after iteration 176: 41.236713\n",
      "Cost after iteration 177: 41.225349\n",
      "Cost after iteration 178: 41.216357\n",
      "Cost after iteration 179: 41.209716\n",
      "Cost after iteration 180: 41.205407\n",
      "Cost after iteration 181: 41.203409\n",
      "Cost after iteration 182: 41.203702\n",
      "Cost after iteration 183: 41.206266\n",
      "Cost after iteration 184: 41.211081\n",
      "Cost after iteration 185: 41.218129\n",
      "Cost after iteration 186: 41.227389\n",
      "Cost after iteration 187: 41.238842\n",
      "Cost after iteration 188: 41.252468\n",
      "Cost after iteration 189: 41.268250\n",
      "Cost after iteration 190: 41.286167\n",
      "Cost after iteration 191: 41.306201\n",
      "Cost after iteration 192: 41.328334\n",
      "Cost after iteration 193: 41.352546\n",
      "Cost after iteration 194: 41.378819\n",
      "Cost after iteration 195: 41.407136\n",
      "Cost after iteration 196: 41.437477\n",
      "Cost after iteration 197: 41.469824\n",
      "Cost after iteration 198: 41.504161\n",
      "Cost after iteration 199: 41.540468\n",
      "Cost after iteration 200: 41.578728\n",
      "Cost after iteration 201: 41.618924\n",
      "Cost after iteration 202: 41.661038\n",
      "Cost after iteration 203: 41.705052\n",
      "Cost after iteration 204: 41.750950\n",
      "Cost after iteration 205: 41.798715\n",
      "Cost after iteration 206: 41.848329\n",
      "Cost after iteration 207: 41.899775\n",
      "Cost after iteration 208: 41.953038\n",
      "Cost after iteration 209: 42.008099\n",
      "Cost after iteration 210: 42.064943\n",
      "Cost after iteration 211: 42.123553\n",
      "Cost after iteration 212: 42.183913\n",
      "Cost after iteration 213: 42.246006\n",
      "Cost after iteration 214: 42.309817\n",
      "Cost after iteration 215: 42.375330\n",
      "Cost after iteration 216: 42.442529\n",
      "Cost after iteration 217: 42.511397\n",
      "Cost after iteration 218: 42.581920\n",
      "Cost after iteration 219: 42.654081\n",
      "Cost after iteration 220: 42.727866\n",
      "Cost after iteration 221: 42.803259\n",
      "Cost after iteration 222: 42.880245\n",
      "Cost after iteration 223: 42.958809\n",
      "Cost after iteration 224: 43.038935\n",
      "Cost after iteration 225: 43.120609\n",
      "Cost after iteration 226: 43.203816\n",
      "Cost after iteration 227: 43.288541\n",
      "Cost after iteration 228: 43.374771\n",
      "Cost after iteration 229: 43.462489\n",
      "Cost after iteration 230: 43.551682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 231: 43.642336\n",
      "Cost after iteration 232: 43.734436\n",
      "Cost after iteration 233: 43.827968\n",
      "Cost after iteration 234: 43.922919\n",
      "Cost after iteration 235: 44.019274\n",
      "Cost after iteration 236: 44.117019\n",
      "Cost after iteration 237: 44.216141\n",
      "Cost after iteration 238: 44.316627\n",
      "Cost after iteration 239: 44.418462\n",
      "Cost after iteration 240: 44.521633\n",
      "Cost after iteration 241: 44.626128\n",
      "Cost after iteration 242: 44.731932\n",
      "Cost after iteration 243: 44.839033\n",
      "Cost after iteration 244: 44.947417\n",
      "Cost after iteration 245: 45.057072\n",
      "Cost after iteration 246: 45.167985\n",
      "Cost after iteration 247: 45.280143\n",
      "Cost after iteration 248: 45.393533\n",
      "Cost after iteration 249: 45.508142\n",
      "Cost after iteration 250: 45.623959\n",
      "Cost after iteration 251: 45.740971\n",
      "Cost after iteration 252: 45.859165\n",
      "Cost after iteration 253: 45.978529\n",
      "Cost after iteration 254: 46.099051\n",
      "Cost after iteration 255: 46.220719\n",
      "Cost after iteration 256: 46.343521\n",
      "Cost after iteration 257: 46.467445\n",
      "Cost after iteration 258: 46.592480\n",
      "Cost after iteration 259: 46.718612\n",
      "Cost after iteration 260: 46.845832\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-52b1bfab5cfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-124-9d96c551f322>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X, Y, num_iterations, learning_rate, print_cost)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mT_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0ma0\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"da0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-122-37eaa2e5cf76>\u001b[0m in \u001b[0;36mlstm_backward\u001b[1;34m(a, caches, YH)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_cell_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mda_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdc_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYH\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mdWf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dWf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-121-f6b5dada2595>\u001b[0m in \u001b[0;36mlstm_cell_backward\u001b[1;34m(da_next, dc_next, cache, y_h)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mconcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_a\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mdWf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mdWi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mdWc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdcct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters,a0 = model(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    features = []\n",
    "    inp = input(\">\")\n",
    "    if inp == 'exit':\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
